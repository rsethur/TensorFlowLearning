{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Layer Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup MPL (needs to be done before plt is imported)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "with tf.name_scope('dataprep'):\n",
    "    mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  (55000, 784)\n",
      "Testing data:  (10000, 784)\n",
      "Validation data:  (5000, 784)\n",
      "28 * 28 = 784 pixels of greyscale data\n"
     ]
    }
   ],
   "source": [
    "print \"Training data: \", mnist.train.images.shape\n",
    "print \"Testing data: \", mnist.test.images.shape\n",
    "print \"Validation data: \", mnist.validation.images.shape\n",
    "print \"28 * 28 = 784 pixels of greyscale data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAFfCAYAAADptc+BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZkw8s/dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1917e26ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "imgplot = ax.imshow(mnist.train.images[1].reshape(28,28), interpolation='nearest', cmap=mpl.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network Topology\n",
    "n_input    = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128 \n",
    "n_classes  = 10\n",
    "\n",
    "#Weight should be initialized from a Gaussian with standard deviation equal to weight_scale, \n",
    "#and biases should be initialized to zero\n",
    "weight_scale=0.1\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "reg = 1e-6\n",
    "num_epochs = 10\n",
    "num_train = mnist.train.images.shape[0]\n",
    "iterations_per_epoch = max(num_train / batch_size, 1)\n",
    "num_iterations = num_epochs * iterations_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "print num_iterations\n",
    "print iterations_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Inputs\n",
    "with tf.name_scope('inputs'):\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name=\"X-input\")\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
    "\n",
    "# Weights (Variables)\n",
    "with tf.name_scope('weights'):    \n",
    "    layer1_W = tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=weight_scale), name=\"layer1_weights\")\n",
    "    layer1_b = tf.Variable(tf.zeros([n_hidden_1]), name=\"layer1_bias\")\n",
    "    #layer1_b = tf.Variable(tf.random_normal([n_hidden_1]), name=\"layer1_bias\")\n",
    "    layer2_W = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=weight_scale), name=\"layer2_weights\")\n",
    "    layer2_b = tf.Variable(tf.zeros([n_hidden_2]), name=\"layer2_bias\")\n",
    "    #layer2_b = tf.Variable(tf.random_normal([n_hidden_2]), name=\"layer2_bias\")\n",
    "    layer3_W = tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=weight_scale), name=\"layer3_weights\")\n",
    "    layer3_b = tf.Variable(tf.zeros([n_classes]), name=\"layer3_bias\")    \n",
    "    #layer3_b = tf.Variable(tf.random_normal([n_classes]), name=\"layer3_bias\")\n",
    "\n",
    "# Operations\n",
    "with tf.name_scope('Model'):\n",
    "    layer1_activations = tf.nn.sigmoid(tf.matmul(X, layer1_W) + layer1_b)\n",
    "    layer2_activations = tf.nn.sigmoid(tf.matmul(layer1_activations, layer2_W) + layer2_b)\n",
    "    scores = tf.matmul(layer2_activations, layer3_W) + layer3_b\n",
    "\n",
    "#better to use tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(scores, y) ) #+ reg * tf.nn.l2_loss(layer3_W)\n",
    "\n",
    "# Train\n",
    "with tf.name_scope('train'):\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)    \n",
    "\n",
    "with tf.name_scope('trainPrediction'):\n",
    "    prediction = tf.nn.softmax(scores)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(prediction,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "with tf.name_scope('Summaries'):\n",
    "    tr_loss_summary_op = tf.scalar_summary('training loss', loss)\n",
    "    tr_acc_summary_op = tf.scalar_summary(\"training accuracy\", accuracy)\n",
    "    train_summary_op = tf.merge_summary([tr_loss_summary_op, tr_acc_summary_op])\n",
    "    \n",
    "    val_acc_summary_op = tf.scalar_summary(\"validation accuracy\", accuracy)        \n",
    "\n",
    "# Initializing the variables\n",
    "with tf.name_scope('globalOps'):          \n",
    "    init = tf.initialize_all_variables()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy:  0.9772\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "writer = tf.train.SummaryWriter('./ThreeLayerNet2', sess.graph)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for step in xrange(num_iterations):\n",
    "    minibatchX, minibatchy = mnist.train.next_batch(batch_size)        \n",
    "    _ = sess.run([optimizer], feed_dict = {X:minibatchX, y:minibatchy})        \n",
    "    \n",
    "    #compute loss & accuracy and log to TensorBoard\n",
    "    if (step % display_step == 0):\n",
    "        _, tr_summ = sess.run([accuracy, train_summary_op], feed_dict = {X:minibatchX, y:minibatchy})\n",
    "        _, val_summ = sess.run([accuracy, val_acc_summary_op], feed_dict = {X:mnist.validation.images, y:mnist.validation.labels})\n",
    "        writer.add_summary(tr_summ, step)\n",
    "        writer.add_summary(val_summ, step)    \n",
    "    \n",
    "#Final eval\n",
    "print \"Test Set Accuracy: \", sess.run(accuracy,feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "print \"done\"\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
